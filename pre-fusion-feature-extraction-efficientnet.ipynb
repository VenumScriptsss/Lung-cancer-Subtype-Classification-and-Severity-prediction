{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12233147,"sourceType":"datasetVersion","datasetId":7707738}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport cv2\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D, GlobalAveragePooling2D, Concatenate, GlobalMaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import ResNet50\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\n\nfrom keras.metrics import Recall,Precision\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n# from keras import models, layers\nfrom keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom IPython.core.interactiveshell import InteractiveShell","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:01.043258Z","iopub.execute_input":"2025-07-29T16:00:01.043771Z","iopub.status.idle":"2025-07-29T16:00:01.054498Z","shell.execute_reply.started":"2025-07-29T16:00:01.043736Z","shell.execute_reply":"2025-07-29T16:00:01.053600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\n\n\ndef load_dataset_with_parent_labels(root_path):\n    T_df = []\n    N_df = []\n    M_df = []\n    \n    root_path = Path(root_path)\n    # data = []\n    \n    # Iterate through each parent folder (label)\n    for parent_dir in root_path.iterdir():\n        if parent_dir.is_dir():  # Ensure it's a directory\n            # label = label_dir.name\n            if parent_dir.name == \"M\":\n                for subcat in (parent_dir/\"Fused_PT_CT\").iterdir():\n                    label = subcat.name.split(\"-\")[-1] # getting the sub class name\n                    for img_path in subcat.glob('*.png'):\n                        # Skip ground truth images (ending with 'GT')\n                        if not img_path.stem.endswith('GT'):\n                            M_df.append({\n                                'path': str(img_path),\n                                'label': label\n                            })\n                M_df = pd.DataFrame(M_df)            \n            \n            if parent_dir.name == 'T':\n                    for subcat in parent_dir.iterdir():\n                        label = subcat.name.split(\"-\")[-1] # getting the sub class name\n                        if label in [\"T1a\", \"T1c\", \"T4\"] or 'Fused' in subcat.name:\n                        \n                            for img_path in subcat.glob('*.png'):\n                                # Skip ground truth images (ending with 'GT')\n                                if not img_path.stem.endswith('GT'):\n                                    T_df.append({\n                                        'path': str(img_path),\n                                        'label': label\n                                    })\n                    T_df = pd.DataFrame(T_df)            \n            else:\n                \n                for subcat in parent_dir.iterdir():\n                    if 'Fused' in subcat.name:\n                        label = subcat.name.split(\"-\")[-1]\n                        for img_path in subcat.glob('*.png'):\n                        # Skip ground truth images (ending with 'GT')\n                            if not img_path.stem.endswith('GT'):\n                                N_df.append({\n                                    'path': str(img_path),\n                                    'label': label\n                                })\n                N_df = pd.DataFrame(N_df)\n                            \n    return T_df, M_df, N_df\n    \nroot_path = \"/kaggle/input/augmented-fusion-new/aug images\"\nT_df, M_df, N_df = load_dataset_with_parent_labels(root_path)\n# Verify\nprint(f\"Total images: {len(T_df)}\")\nprint(\"Label distribution:\")\nprint(\"\\n\",T_df['label'].value_counts())\n\nprint(f\"Total images: {len(M_df)}\")\nprint(\"Label distribution:\")\nprint(\"\\n\",M_df['label'].value_counts())\n\nprint(f\"Total images: {len(N_df)}\")\nprint(\"Label distribution:\")\nprint(N_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:01.056405Z","iopub.execute_input":"2025-07-29T16:00:01.056729Z","iopub.status.idle":"2025-07-29T16:00:01.246105Z","shell.execute_reply.started":"2025-07-29T16:00:01.056705Z","shell.execute_reply":"2025-07-29T16:00:01.245038Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# M Stage","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocessing\n\n\nM_train_df, M_test_df = train_test_split(M_df, test_size=0.2, random_state=2, shuffle=True, stratify=M_df['label'])\n\n# debugging_df, _ = train_test_split(\n#     train_df,\n#     train_size=1,  # 10% of the data\n#     stratify=train_df['label'],  # Maintain class distribution\n#     random_state=42,\n#     shuffle=True\n# )\nbatch_size = 32\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=eff_preprocessing,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest', \n    validation_split=0.2\n)\ntest_generator = ImageDataGenerator(preprocessing_function=eff_preprocessing)\n\nM_train_imgs = train_generator.flow_from_dataframe(\n    dataframe = M_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = True,\n    subset = \"training\"\n)\n\nM_val_imgs = train_generator.flow_from_dataframe(\n    dataframe = M_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size =(224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False,\n    subset = \"validation\"\n)\n\nM_test_imgs = test_generator.flow_from_dataframe(\n    dataframe = M_test_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False\n)  # No augmentation for validation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:11:49.500444Z","iopub.execute_input":"2025-07-29T16:11:49.500858Z","iopub.status.idle":"2025-07-29T16:11:53.191929Z","shell.execute_reply.started":"2025-07-29T16:11:49.500833Z","shell.execute_reply":"2025-07-29T16:11:53.191114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# T Stage","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocessing\n\n\nT_train_df, T_test_df = train_test_split(T_df, test_size=0.2, random_state=2, shuffle=True, stratify=T_df['label'])\n\nbatch_size = 32\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=eff_preprocessing,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest', \n    validation_split=0.2\n)\ntest_generator = ImageDataGenerator(preprocessing_function=eff_preprocessing)\n\nT_train_imgs = train_generator.flow_from_dataframe(\n    dataframe = T_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = True,\n    subset = \"training\"\n)\n\nT_val_imgs = train_generator.flow_from_dataframe(\n    dataframe = T_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size =(224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False,\n    subset = \"validation\"\n)\n\nT_test_imgs = test_generator.flow_from_dataframe(\n    dataframe = T_test_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False\n)  # No augmentation for validation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# N Stage","metadata":{}},{"cell_type":"code","source":"N_train_df, N_test_df = train_test_split(N_df, test_size=0.2, random_state=2, shuffle=True, stratify=N_df['label'])\n\nbatch_size = 32\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=eff_preprocessing,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest', \n    validation_split=0.2\n)\ntest_generator = ImageDataGenerator(preprocessing_function=eff_preprocessing)\n\nN_train_imgs = train_generator.flow_from_dataframe(\n    dataframe = N_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = True,\n    subset = \"training\"\n)\n\nN_val_imgs = train_generator.flow_from_dataframe(\n    dataframe = N_train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size =(224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False,\n    subset = \"validation\"\n)\n\nN_test_imgs = test_generator.flow_from_dataframe(\n    dataframe = N_test_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False\n)  # No augmentation for validation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:11:56.257349Z","iopub.execute_input":"2025-07-29T16:11:56.258468Z","iopub.status.idle":"2025-07-29T16:12:05.031232Z","shell.execute_reply.started":"2025-07-29T16:11:56.258441Z","shell.execute_reply":"2025-07-29T16:12:05.030388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras import mixed_precision\nfrom tensorflow.keras.applications import EfficientNetB0, DenseNet121, DenseNet201, ResNet50\nfrom tensorflow.keras.models import Model\n\n\ndef build_model(class_count, with_gradcam=False):\n    base_model = EfficientNetB0(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights=\"imagenet\",\n    )\n    base_model.trainable = False\n    for layer in base_model.layers[-30:]: #30   reduce the unfreezed layers -->  less complex model\n        layer.trainable = True\n    \n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    \n    x = Dense(256)(x)\n    x = BatchNormalization()(x)  \n    x = Activation('relu')(x)\n    \n    x = Dense(256)(x)\n    x = BatchNormalization()(x)   \n    x = Activation('relu')(x)   \n\n    x = Dense(128)(x)\n    x = Activation('relu')(x)\n    \n    x = Dense(64)(x)\n    x = Activation('relu')(x)\n    \n    classification_output = Dense(class_count, activation='softmax', name='cls_output')(x)\n\n    if with_gradcam:\n        # Output both predictions and last conv layer features\n        model = Model(\n            inputs=base_model.input,\n            outputs={'cls_output':classification_output, \n                     'vis_layer':base_model.get_layer('top_conv').output}\n        )\n    else:\n        # Standard classification model\n        model = Model(inputs=base_model.input,outputs=classification_output)\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:12:10.100314Z","iopub.execute_input":"2025-07-29T16:12:10.100905Z","iopub.status.idle":"2025-07-29T16:12:10.110164Z","shell.execute_reply.started":"2025-07-29T16:12:10.100846Z","shell.execute_reply":"2025-07-29T16:12:10.109119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\ndef evaluate(model, test_imgs, history, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n\n    true_labels = test_imgs.classes\n    pred_probs = model.predict(test_imgs)['cls_output']\n    pred_labels = np.argmax(pred_probs, axis=1)\n    class_labels = list(test_imgs.class_indices.keys())\n\n    report = classification_report(true_labels, pred_labels, target_names=class_labels)\n    print(report)\n    with open(os.path.join(output_dir, \"classification_report.txt\"), \"w\") as f:\n        f.write(report)\n\n    plt.figure(figsize=(12, 5))\n    \n    # Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['cls_output_accuracy'], label='Train Accuracy', marker='o')\n    plt.plot(history.history['val_cls_output_accuracy'], label='Validation Accuracy', marker='x')\n    plt.title('Accuracy Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(os.path.join(output_dir, \"acc.png\"))\n    plt.show()\n    plt.close()\n\n    # Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss', marker='o')\n    plt.plot(history.history['val_loss'], label='Validation Loss', marker='x')\n    plt.title('Loss Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, \"loss.png\"))\n    plt.show()\n    plt.close()\n\n    # Confusion matrix\n    cm = confusion_matrix(true_labels, pred_labels)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix')\n\n    cm_plot_path = os.path.join(output_dir, \"confusion_matrix.png\")\n    plt.savefig(cm_plot_path)\n    plt.close()\n\n    print(f\"\\nSaved classification report, plots to '{output_dir}'\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, output_index=0):\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[model.get_layer(last_conv_layer_name).output, model.output[output_index] if isinstance(model.output, (list, tuple)) else model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        pred_index = tf.argmax(predictions['cls_output'])\n        class_output = predictions['cls_output']\n\n    grads = tape.gradient(class_output, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap + tf.keras.backend.epsilon())\n\n    return heatmap.numpy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\ndef display_gradcam_on_image(img_array, original_img, heatmap, true_label, predicted_label, alpha=0.4):\n\n    heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    superimposed_img = heatmap_color * alpha + original_img\n    superimposed_img = np.uint8(superimposed_img)\n\n    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title(f\"{true_label} Class\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-training the Model on M Stage","metadata":{}},{"cell_type":"code","source":"# train_imgs, val_imgs = load_and_preprocess_data()\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ntraining_samples_num = len(M_train_df)*0.8\n\ninitial_learning_rate = 5e-3\nlr_schedule = ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=(training_samples_num//batch_size)*2,\n    decay_rate=0.4, # reduce by 20%\n    staircase=True)\n\nM_model = build_model(4, with_gradcam=True)\n\nM_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n    loss={'cls_output':'categorical_crossentropy'},\n    metrics=['accuracy']\n)\n\nclass LrValLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, 'numpy'):\n            lr_value = lr.numpy()\n        else:\n            lr_value = tf.keras.backend.get_value(lr)\n        \n        val_loss = logs.get('val_loss')\n        print(f\"            learning rate ={lr_value:.6f}\")\n\nM_history = M_model.fit(\n    M_train_imgs,\n    validation_data=M_val_imgs,\n    epochs=15,\n    callbacks=[\n        LrValLogger()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs('output', exist_ok=True)\nM_model.save('output/M_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:42.880618Z","iopub.status.idle":"2025-07-29T16:00:42.880987Z","shell.execute_reply.started":"2025-07-29T16:00:42.880813Z","shell.execute_reply":"2025-07-29T16:00:42.880826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate(M_model, M_test_imgs, M_history, output_dir=\"evaluation_results_M\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:42.882321Z","iopub.status.idle":"2025-07-29T16:00:42.882576Z","shell.execute_reply.started":"2025-07-29T16:00:42.882454Z","shell.execute_reply":"2025-07-29T16:00:42.882465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_indices = M_train_imgs.class_indices\nclasses = list(class_indices.keys())\n\nX_batch, y_batch = next(M_train_imgs)\nvis_classes = []\n\nfor i in range(min(20, len(X_batch))):\n    img_array = np.expand_dims(X_batch[i], axis=0)\n    true_idx = np.argmax(y_batch[i])\n    true_label = classes[true_idx]\n\n    if true_label in vis_classes:\n        continue\n        \n    vis_classes.append(true_label)\n    \n    # Predict using the model\n    preds = M_model.predict(img_array)['cls_output']\n    \n    # If model has multiple outputs, select correct head\n    if isinstance(preds, (list, tuple)):\n        preds = preds[0]  # or whatever head you care about\n\n    pred_idx = np.argmax(preds[0])\n    predicted_label = classes[pred_idx]\n\n    if true_idx != pred_idx:\n        print(f\"Skipped (True: {true_label}, Pred: {predicted_label})\")\n        continue\n\n    # Grad-CAM\n    heatmap = make_gradcam_heatmap(\n        img_array, M_model, last_conv_layer_name=\"top_conv\", output_index=0\n    )\n\n    # Visualize\n    original_img = X_batch[i]\n    original_img_disp = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n\n    display_gradcam_on_image(img_array, original_img_disp, heatmap, true_label, predicted_label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:42.887782Z","iopub.status.idle":"2025-07-29T16:00:42.888238Z","shell.execute_reply.started":"2025-07-29T16:00:42.888047Z","shell.execute_reply":"2025-07-29T16:00:42.888065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-training the model on N Stage","metadata":{}},{"cell_type":"code","source":"training_samples_num = len(N_train_df)*0.8\n\ninitial_learning_rate = 5e-3\nlr_schedule = ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=(training_samples_num//batch_size)*2,\n    decay_rate=0.4,\n    staircase=True)\n\nN_model = build_model(3, with_gradcam=True)\n\nN_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n    loss={'cls_output':'categorical_crossentropy'},\n    metrics=['accuracy']\n)\n\nclass LrValLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, 'numpy'):\n            lr_value = lr.numpy()\n        else:\n            lr_value = tf.keras.backend.get_value(lr)\n        \n        val_loss = logs.get('val_loss')\n        print(f\"            learning rate ={lr_value:.6f}\")\n\nN_history = N_model.fit(\n    N_train_imgs,\n    validation_data=N_val_imgs,\n    epochs=15,\n    callbacks=[\n        LrValLogger()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_model.save('output/N_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T16:00:42.892138Z","iopub.status.idle":"2025-07-29T16:00:42.892525Z","shell.execute_reply.started":"2025-07-29T16:00:42.892318Z","shell.execute_reply":"2025-07-29T16:00:42.892333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate(M_model, N_test_imgs, N_history, output_dir=\"evaluation_results_N\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_indices = N_train_imgs.class_indices\nclasses = list(class_indices.keys())\n\nX_batch, y_batch = next(N_train_imgs)\nvis_classes = []\n\nfor i in range(min(20, len(X_batch))):\n    img_array = np.expand_dims(X_batch[i], axis=0)\n    true_idx = np.argmax(y_batch[i])\n    true_label = classes[true_idx]\n\n    if true_label in vis_classes:\n        continue\n        \n    vis_classes.append(true_label)\n    \n    # Predict using the model\n    preds = N_model.predict(img_array)['cls_output']\n    \n    # If model has multiple outputs, select correct head\n    if isinstance(preds, (list, tuple)):\n        preds = preds[0]  # or whatever head you care about\n\n    pred_idx = np.argmax(preds[0])\n    predicted_label = classes[pred_idx]\n\n    if true_idx != pred_idx:\n        print(f\"Skipped (True: {true_label}, Pred: {predicted_label})\")\n        continue\n\n    # Grad-CAM\n    heatmap = make_gradcam_heatmap(\n        img_array, N_model, last_conv_layer_name=\"top_conv\", output_index=0\n    )\n\n    # Visualize\n    original_img = X_batch[i]\n    original_img_disp = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n\n    display_gradcam_on_image(img_array, original_img_disp, heatmap, true_label, predicted_label)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-training the model on T stage","metadata":{}},{"cell_type":"code","source":"training_samples_num = len(Ttrain_df)*0.8\n\ninitial_learning_rate = 5e-3\nlr_schedule = ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=(training_samples_num//batch_size)*2,\n    decay_rate=0.4,\n    staircase=True)\n\nT_model = build_model(3, with_gradcam=True)\n\nT_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n    loss={'cls_output':'categorical_crossentropy'},\n    metrics=['accuracy']\n)\n\nclass LrValLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, 'numpy'):\n            lr_value = lr.numpy()\n        else:\n            lr_value = tf.keras.backend.get_value(lr)\n        \n        val_loss = logs.get('val_loss')\n        print(f\"            learning rate ={lr_value:.6f}\")\n\nT_history = T_model.fit(\n    T_train_imgs,\n    validation_data=T_val_imgs,\n    epochs=15,\n    callbacks=[\n        LrValLogger()\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"T_model.save('output/N_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate(T_model, T_test_imgs, T_history, output_dir=\"evaluation_results_T\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_indices = T_train_imgs.class_indices\nclasses = list(class_indices.keys())\n\nX_batch, y_batch = next(T_train_imgs)\nvis_classes = []\n\nfor i in range(min(20, len(X_batch))):\n    img_array = np.expand_dims(X_batch[i], axis=0)\n    true_idx = np.argmax(y_batch[i])\n    true_label = classes[true_idx]\n\n    if true_label in vis_classes:\n        continue\n        \n    vis_classes.append(true_label)\n    \n    # Predict using the model\n    preds = T_model.predict(img_array)['cls_output']\n    \n    # If model has multiple outputs, select correct head\n    if isinstance(preds, (list, tuple)):\n        preds = preds[0]  # or whatever head you care about\n\n    pred_idx = np.argmax(preds[0])\n    predicted_label = classes[pred_idx]\n\n    if true_idx != pred_idx:\n        print(f\"Skipped (True: {true_label}, Pred: {predicted_label})\")\n        continue\n\n    # Grad-CAM\n    heatmap = make_gradcam_heatmap(\n        img_array, T_model, last_conv_layer_name=\"top_conv\", output_index=0\n    )\n\n    # Visualize\n    original_img = X_batch[i]\n    original_img_disp = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n\n    display_gradcam_on_image(img_array, original_img_disp, heatmap, true_label, predicted_label)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}