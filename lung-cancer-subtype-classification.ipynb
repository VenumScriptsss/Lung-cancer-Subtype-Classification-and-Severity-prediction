{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11433512,"sourceType":"datasetVersion","datasetId":7161213},{"sourceId":11993841,"sourceType":"datasetVersion","datasetId":7544083},{"sourceId":12005867,"sourceType":"datasetVersion","datasetId":7552764}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport cv2\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nimport matplotlib.pyplot as plt\nimport tensorflow \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D, GlobalAveragePooling2D, Concatenate, GlobalMaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import ResNet50\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\n\nfrom keras.metrics import Recall,Precision\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n# from keras import models, layers\nfrom keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom IPython.core.interactiveshell import InteractiveShell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:53:50.258101Z","iopub.execute_input":"2025-07-15T07:53:50.258441Z","iopub.status.idle":"2025-07-15T07:53:50.267582Z","shell.execute_reply.started":"2025-07-15T07:53:50.258422Z","shell.execute_reply":"2025-07-15T07:53:50.266968Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\n\ndef load_dataset_with_parent_labels(root_path, excluded_classes):\n\n    root_path = Path(root_path)\n    data = []\n    \n    for label_dir in root_path.iterdir():\n        label = label_dir.name\n        if label_dir.is_dir() and label not in excluded_classes:  # Ensure it's a directory\n            \n            for img_path in label_dir.glob('**/*.png'):\n                if not img_path.stem.endswith('GT'):\n                    data.append({\n                        'path': str(img_path),\n                        'label': label\n                    })\n    \n    return pd.DataFrame(data)\n    \nroot_path = \"/kaggle/input/newly-fused-lung-pet-ct-dx3/Newly Fused Dataset\"\naug_root_path = \"/kaggle/input/augmented-fused-staging-dx\"\nnone_aug_df = load_dataset_with_parent_labels(root_path, ['smallsellcarcinoma', 'squamouscellcarcinoma'])\naug_df = load_dataset_with_parent_labels(aug_root_path, ['M', 'T', 'N', 'adenocarcinoma'])\n\n# concatenating both dfs\ndf = pd.concat([aug_df, none_aug_df], ignore_index=True)\n\nprint(f\"Total images: {len(df)}\")\nprint(\"Label distribution:\")\nprint(df['label'].value_counts())    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n\n# def custom_undersample(df, sampling_dict):\n#     \"\"\"\n#     Custom undersampling based on target counts per class.\n#     Classes not in the dictionary remain unchanged.\n#     \"\"\"\n#     np.random.seed(42)  # For reproducibility\n#     dfs = []\n    \n#     for class_name, target_count in sampling_dict.items():\n#         class_samples = df[df['label'] == class_name]\n#         if len(class_samples) > target_count:\n#             # Undersample if class is larger than target\n#             selected_indices = np.random.choice(\n#                 class_samples.index,\n#                 size=target_count,\n#                 replace=False\n#             )\n#             dfs.append(df.loc[selected_indices])\n#         else:\n#             # Keep all if class is smaller than target\n#             dfs.append(class_samples)\n    \n#     # Add classes not in the dictionary (unchanged)\n#     other_classes = df[~df['label'].isin(sampling_dict.keys())]\n#     if not other_classes.empty:\n#         dfs.append(other_classes)\n    \n#     return pd.concat(dfs).sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.427501Z","iopub.execute_input":"2025-07-15T07:54:11.427803Z","iopub.status.idle":"2025-07-15T07:54:11.431966Z","shell.execute_reply.started":"2025-07-15T07:54:11.427779Z","shell.execute_reply":"2025-07-15T07:54:11.431398Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"filtered_df = df[df['label'].isin(['smallcellcarcinoma', 'adenocarcinoma', 'squamouscellcarcinoma'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.470011Z","iopub.execute_input":"2025-07-15T07:54:11.470383Z","iopub.status.idle":"2025-07-15T07:54:11.489482Z","shell.execute_reply.started":"2025-07-15T07:54:11.470358Z","shell.execute_reply":"2025-07-15T07:54:11.488654Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class_counts = filtered_df['label'].value_counts().sort_index()\nprint(class_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.490371Z","iopub.execute_input":"2025-07-15T07:54:11.490669Z","iopub.status.idle":"2025-07-15T07:54:11.507257Z","shell.execute_reply.started":"2025-07-15T07:54:11.490651Z","shell.execute_reply":"2025-07-15T07:54:11.506751Z"}},"outputs":[{"name":"stdout","text":"label\nadenocarcinoma           3352\nsmallcellcarcinoma       3430\nsquamouscellcarcinoma    2862\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from tensorflow.keras.applications.efficientnet import preprocess_input\n\ntrain_df, test_df = train_test_split(filtered_df, test_size=0.2, random_state=2, shuffle=True, stratify = filtered_df['label']) \n\nbatch_size = 64\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    validation_split=0.2\n)\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_imgs = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = True,\n    subset = \"training\"\n)\n\nval_imgs = train_generator.flow_from_dataframe(\n    dataframe = train_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size =(224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False,\n    subset = \"validation\"\n)\n\ntest_imgs = test_generator.flow_from_dataframe(\n    dataframe = test_df,\n    x_col = \"path\",\n    y_col = \"label\",\n    target_size = (224,224),\n    color_mode = \"rgb\",\n    class_mode = \"categorical\",\n    batch_size = batch_size,\n    shuffle = False\n)  # No augmentation for validation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.507923Z","iopub.execute_input":"2025-07-15T07:54:11.508121Z","iopub.status.idle":"2025-07-15T07:54:11.845653Z","shell.execute_reply.started":"2025-07-15T07:54:11.508097Z","shell.execute_reply":"2025-07-15T07:54:11.845076Z"}},"outputs":[{"name":"stdout","text":"Found 6172 validated image filenames belonging to 3 classes.\nFound 1543 validated image filenames belonging to 3 classes.\nFound 1929 validated image filenames belonging to 3 classes.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(pd.Series(train_imgs.classes).value_counts())  # Per-class counts\nprint(pd.Series(val_imgs.classes).value_counts())  # Per-class counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.846383Z","iopub.execute_input":"2025-07-15T07:54:11.846660Z","iopub.status.idle":"2025-07-15T07:54:11.854064Z","shell.execute_reply.started":"2025-07-15T07:54:11.846641Z","shell.execute_reply":"2025-07-15T07:54:11.853214Z"}},"outputs":[{"name":"stdout","text":"1    2176\n0    2142\n2    1854\nName: count, dtype: int64\n1    568\n0    539\n2    436\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"images, labels = next(train_imgs)\nprint(\"Labels shape:\", labels.shape)\nprint(\"One-hot example:\", labels[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:11.854869Z","iopub.execute_input":"2025-07-15T07:54:11.855153Z","iopub.status.idle":"2025-07-15T07:54:12.141941Z","shell.execute_reply.started":"2025-07-15T07:54:11.855135Z","shell.execute_reply":"2025-07-15T07:54:12.141375Z"}},"outputs":[{"name":"stdout","text":"Labels shape: (64, 3)\nOne-hot example: [0. 1. 0.]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"images, _ = next(train_imgs)\nprint(\"Min pixel value:\", images.min())\nprint(\"Max pixel value:\", images.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:12.143600Z","iopub.execute_input":"2025-07-15T07:54:12.143804Z","iopub.status.idle":"2025-07-15T07:54:12.432662Z","shell.execute_reply.started":"2025-07-15T07:54:12.143788Z","shell.execute_reply":"2025-07-15T07:54:12.432011Z"}},"outputs":[{"name":"stdout","text":"Min pixel value: 0.0\nMax pixel value: 255.0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0, DenseNet121, DenseNet201, ResNet50\nfrom tensorflow.keras.models import Model\n\ndef build_model():\n    base_model = EfficientNetB0(\n        input_shape=(224, 224, 3),\n        include_top=False,\n        weights=\"imagenet\",\n    )\n    base_model.trainable = False\n    for layer in base_model.layers[-20:]: #30   reduce the unfreezed layers -->  less complex model\n        layer.trainable = True\n    \n    \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    \n    x = Dense(256)(x)\n    x = BatchNormalization()(x)  \n    x = Activation('relu')(x)\n    \n    x = Dense(256)(x)\n    x = BatchNormalization()(x)   \n    x = Activation('relu')(x)   \n\n    x = Dense(128)(x)\n    x = Activation('relu')(x)   \n\n    x = Dense(64)(x)\n    x = Activation('relu')(x)   \n\n    outputs = Dense(3, activation='softmax')(x),\n\n    model = Model(inputs=base_model.input, outputs=outputs)\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:12.438804Z","iopub.execute_input":"2025-07-15T07:54:12.439120Z","iopub.status.idle":"2025-07-15T07:54:12.465726Z","shell.execute_reply.started":"2025-07-15T07:54:12.439085Z","shell.execute_reply":"2025-07-15T07:54:12.465126Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ntraining_samples_num = len(train_df)*0.8\n\ninitial_learning_rate = 5e-3\nlr_schedule = ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=(training_samples_num//batch_size)*2,\n    decay_rate=0.4, # reduce by 20%\n    staircase=True)\n\nmodel = build_model()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nclass LrValLogger(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = self.model.optimizer.learning_rate\n        if hasattr(lr, 'numpy'):\n            lr_value = lr.numpy()\n        else:\n            lr_value = tf.keras.backend.get_value(lr)\n        \n        val_loss = logs.get('val_loss')\n        print(f\"            learning rate ={lr_value:.6f}\")\n\nhistory = model.fit(\n    train_imgs,\n    validation_data=val_imgs,\n    epochs=15,\n    callbacks=[\n        LrValLogger()\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T07:54:12.487889Z","iopub.execute_input":"2025-07-15T07:54:12.488168Z","iopub.status.idle":"2025-07-15T08:04:57.133889Z","shell.execute_reply.started":"2025-07-15T07:54:12.488144Z","shell.execute_reply":"2025-07-15T08:04:57.133074Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.5290 - loss: 0.9473            learning rate =0.005000\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 618ms/step - accuracy: 0.5301 - loss: 0.9455 - val_accuracy: 0.7660 - val_loss: 1.7320\nEpoch 2/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.7878 - loss: 0.4820            learning rate =0.002000\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 412ms/step - accuracy: 0.7881 - loss: 0.4814 - val_accuracy: 0.8276 - val_loss: 0.7370\nEpoch 3/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9062 - loss: 0.2440            learning rate =0.002000\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 416ms/step - accuracy: 0.9063 - loss: 0.2436 - val_accuracy: 0.9339 - val_loss: 0.1998\nEpoch 4/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.9462 - loss: 0.1384            learning rate =0.000800\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 419ms/step - accuracy: 0.9461 - loss: 0.1385 - val_accuracy: 0.9443 - val_loss: 0.1487\nEpoch 5/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9642 - loss: 0.0972            learning rate =0.000800\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 423ms/step - accuracy: 0.9643 - loss: 0.0970 - val_accuracy: 0.9695 - val_loss: 0.0889\nEpoch 6/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9799 - loss: 0.0551            learning rate =0.000320\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 402ms/step - accuracy: 0.9799 - loss: 0.0551 - val_accuracy: 0.9566 - val_loss: 0.1227\nEpoch 7/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9893 - loss: 0.0333            learning rate =0.000320\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 397ms/step - accuracy: 0.9893 - loss: 0.0334 - val_accuracy: 0.9572 - val_loss: 0.1212\nEpoch 8/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9894 - loss: 0.0340            learning rate =0.000128\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 390ms/step - accuracy: 0.9894 - loss: 0.0340 - val_accuracy: 0.9780 - val_loss: 0.0600\nEpoch 9/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9909 - loss: 0.0272            learning rate =0.000128\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 398ms/step - accuracy: 0.9909 - loss: 0.0272 - val_accuracy: 0.9793 - val_loss: 0.0590\nEpoch 10/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.9899 - loss: 0.0270            learning rate =0.000051\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 401ms/step - accuracy: 0.9899 - loss: 0.0270 - val_accuracy: 0.9812 - val_loss: 0.0520\nEpoch 11/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.9928 - loss: 0.0206            learning rate =0.000051\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 405ms/step - accuracy: 0.9928 - loss: 0.0207 - val_accuracy: 0.9806 - val_loss: 0.0544\nEpoch 12/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9945 - loss: 0.0172            learning rate =0.000020\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 399ms/step - accuracy: 0.9945 - loss: 0.0172 - val_accuracy: 0.9819 - val_loss: 0.0546\nEpoch 13/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9960 - loss: 0.0134            learning rate =0.000020\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 409ms/step - accuracy: 0.9960 - loss: 0.0134 - val_accuracy: 0.9831 - val_loss: 0.0503\nEpoch 14/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9934 - loss: 0.0214            learning rate =0.000008\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 405ms/step - accuracy: 0.9934 - loss: 0.0214 - val_accuracy: 0.9825 - val_loss: 0.0512\nEpoch 15/15\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.9938 - loss: 0.0193            learning rate =0.000008\n\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 400ms/step - accuracy: 0.9938 - loss: 0.0193 - val_accuracy: 0.9825 - val_loss: 0.0520\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def trainingPlots(history):\n    # Accuracy plot\n    plt.figure(figsize=(12, 6))\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend()\n    # plt.savefig('accuracy_plot.png')\n    plt.show()\n    plt.close()\n    \n    # Loss plot\n    plt.figure(figsize=(12, 6))\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend()\n    # plt.savefig('loss_plot.png')\n    plt.show()\n    plt.close()    \n    # Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='x')\n    plt.title('Accuracy Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n\n    # Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss', marker='o')\n    plt.plot(history.history['val_loss'], label='Validation Loss', marker='x')\n    plt.title('Loss Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    # plt.show()\n\n    plt.tight_layout()\n    acc_loss_plot_path = os.path.join(output_dir, \"accuracy_loss_plot.png\")\n    plt.savefig(acc_loss_plot_path)\n    plt.close()\n\ndef modelEvaluation(model, test_imgs):\n    y_pred = model.predict(test_imgs)\n    y_pred = np.argmax(y_pred, axis=1)\n    \n    y_true = test_imgs.labels\n    \n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=test_imgs.class_indices.keys(),\n                yticklabels=test_imgs.class_indices.keys())\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.savefig('confusion_matrix.png')\n    plt.show()\n    plt.close()\n    \n    report = classification_report(y_true, y_pred, target_names=test_imgs.class_indices.keys())\n    with open('classification_report.txt', 'w') as f:\n        f.write(report)\n\ntrainingPlots(history)\nmodelEvaluation(model, test_imgs)\n\nmodel.save('lung_classification_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        pred_index = tf.argmax(predictions[0])\n        print(pred_index)\n        class_output = predictions[:, pred_index]\n\n    grads = tape.gradient(class_output, conv_outputs)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0] \n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + tf.keras.backend.epsilon())\n    \n    return heatmap.numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T08:39:05.512478Z","iopub.execute_input":"2025-07-15T08:39:05.512751Z","iopub.status.idle":"2025-07-15T08:39:05.518894Z","shell.execute_reply.started":"2025-07-15T08:39:05.512732Z","shell.execute_reply":"2025-07-15T08:39:05.518219Z"}},"outputs":[],"execution_count":59}]}